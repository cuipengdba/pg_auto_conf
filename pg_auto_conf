import os
import re
import shutil
import subprocess
import sys


def get_system_info_with_commands():
    """尝试通过执行系统命令获取CPU核心数和内存大小。"""
    cpu_cores = None
    mem_gb = None

    # Determine if 'capture_output' is supported (Python 3.7+)
    # If not, fall back to stdout=PIPE, stderr=PIPE
    _use_capture_output = sys.version_info >= (3, 7)

    # 获取CPU核心数
    try:
        if _use_capture_output:
            lscpu_result = subprocess.run(['lscpu'], capture_output=True, text=True, check=True)
            lscpu_output_stdout = lscpu_result.stdout
        else:
            # Fallback for Python < 3.7
            lscpu_process = subprocess.Popen(['lscpu'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            lscpu_stdout_bytes, _ = lscpu_process.communicate()
            lscpu_output_stdout = lscpu_stdout_bytes.decode('utf-8')
            if lscpu_process.returncode != 0:
                raise subprocess.CalledProcessError(lscpu_process.returncode, 'lscpu', lscpu_output_stdout)

        for line in lscpu_output_stdout.splitlines():
            if "CPU(s):" in line and "On-line" not in line:  # 排除'On-line CPU(s) list:'
                match = re.search(r'CPU\(s\):\s+(\d+)', line)
                if match:
                    cpu_cores = int(match.group(1))
                    break
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("警告: 无法执行 'lscpu' 命令来获取CPU信息。")
    except Exception as e:
        print(f"获取CPU信息时发生未知错误: {e}")

    # 获取总内存 (GB)
    try:
        if _use_capture_output:
            free_result = subprocess.run(['free', '-g'], capture_output=True, text=True, check=True)
            free_output_stdout = free_result.stdout
        else:
            # Fallback for Python < 3.7
            free_process = subprocess.Popen(['free', '-g'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            free_stdout_bytes, _ = free_process.communicate()
            free_output_stdout = free_stdout_bytes.decode('utf-8')
            if free_process.returncode != 0:
                raise subprocess.CalledProcessError(free_process.returncode, 'free -g', free_output_stdout)

        for line in free_output_stdout.splitlines():
            if "Mem:" in line:
                parts = line.split()
                if len(parts) >= 2:
                    mem_gb = int(parts[1])  # free -g 的第二列是总内存
                    break
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("警告: 无法执行 'free -g' 命令来获取内存信息。")
    except Exception as e:
        print(f"获取内存信息时发生未知错误: {e}")

    return cpu_cores, mem_gb


def get_user_input_system_info():
    """手动获取用户输入的系统信息。"""
    while True:
        try:
            cpu_cores = int(input("请输入CPU核心数: "))
            if cpu_cores <= 0:
                raise ValueError
            break
        except ValueError:
            print("无效的CPU核心数，请输入正整数。")

    while True:
        try:
            mem_gb = int(input("请输入总内存大小 (GB): "))
            if mem_gb <= 0:
                raise ValueError
            break
        except ValueError:
            print("无效的内存大小，请输入正整数。")
    return cpu_cores, mem_gb


def get_workload_type():
    """获取用户选择的工作负载类型。"""
    workload_map = {
        "1": "OLTP",
        "2": "OLAP"
    }

    while True:
        try:
            workload_select = input("请选择负载类型 (1.OLTP / 2.OLAP): ").strip().upper()
            workload = workload_map[workload_select]
            if workload in ['OLTP', 'OLAP']:
                return workload
            else:
                print("无效的负载类型，请选择 'OLTP' 或 'OLAP'。")
        except ValueError:
            print("无效的负载类型，请输入正确的数字")


def get_autovacuum_strategy():
    """获取用户选择的Autovacuum策略。"""
    vacuum_map = {
        "1": "Aggressive",
        "2": "Normal",
        "3": "Conservative"
    }
    while True:
        try:
            strategy_num = input("请选择autovacuum策略 (1.Aggressive / 2.Normal / 3.Conservative): ").strip()
            strategy = vacuum_map[strategy_num]
            if strategy in ['Aggressive', 'Normal', 'Conservative']:
                return strategy
            else:
                print("无效的策略，请选择 'Aggressive', 'Normal' 或 'Conservative'。")
        except ValueError as e:
            print("无效的选项，请输入正确的数字")


def generate_config(cpu_cores, mem_gb, workload_type, autovacuum_strategy,
                    is_vm, storage_type, is_high_performance_system,
                    is_primary_server, max_connections=100, replication_type=None, rpo_tolerance=None,
                    is_cow_filesystem=None, expected_concurrent_analytical_queries=None,
                    log_slow_query_threshold_ms=None, log_destination_type=None,
                    log_rotation_age_hours=None, log_rotation_size_mb=None,
                    standby_usage_type=None, replica_count=None, fine_tune_mode=False):
    """根据输入参数生成PostgreSQL配置字典。"""
    config = {}

    # 根据系统性能概况设置基础参数
    if is_high_performance_system:
        # 高性能系统参数建议 [2, 3, 4]
        mem_multiplier_shared_buffers = 0.35  # shared_buffers 30-40% RAM [5, 2, 6]
        mem_multiplier_effective_cache = 0.75  # effective_cache_size 75% RAM [2, 3]
        mem_multiplier_maintenance_work = 0.05  # maintenance_work_mem 1GB+ (约5% RAM) [3, 7]
        wal_buffers_mb = 64  # wal_buffers 64MB+ [1, 2, 3, 6, 8, 7, 9]
        max_wal_size_gb = 4  # max_wal_size 4GB+ [3, 10]
        autovacuum_max_workers_base = 5  # autovacuum_max_workers 5-10 [3, 6, 11]
        autovacuum_naptime_s = 15  # autovacuum_naptime 15s-30s [3, 12]
        autovacuum_cost_limit = 1000  # autovacuum_cost_limit 500-1000 [3, 6, 11]
    else:  # 低性能 / 资源受限系统 [1, 13, 5, 4, 14]
        mem_multiplier_shared_buffers = 0.25  # shared_buffers 15-20% RAM [1, 4]
        mem_multiplier_effective_cache = 0.60  # effective_cache_size 50-75% RAM [1, 3]
        mem_multiplier_maintenance_work = 0.02  # maintenance_work_mem 128MB-512MB (约2% RAM) [3]
        wal_buffers_mb = 32  # wal_buffers 16MB-32MB [3]
        max_wal_size_gb = 2  # max_wal_size 1GB-2GB [3]
        autovacuum_max_workers_base = 3  # 默认3个 [3, 11]
        autovacuum_naptime_s = 60  # 默认60s [11, 12]
        autovacuum_cost_limit = 200  # 默认200 [3, 11]

    # 1. 内存参数
    # shared_buffers: 专用数据库服务器通常25% RAM，最高40% [1, 13, 5, 15, 16, 8]。
    # EDB建议专用服务器不超过10GB [2]。
    if is_high_performance_system:
        shared_buffers = int(mem_gb * mem_multiplier_shared_buffers)
    else:
        shared_buffers = int(mem_gb * mem_multiplier_shared_buffers)
        # 低端机使用MB，至少64MB，避免过度分配导致交换 [1, 5, 16]
    config['shared_buffers'] = f"{shared_buffers}GB"

    # effective_cache_size: 告知查询规划器可用缓存总大小，通常为总RAM的50%-75% [1, 2, 17, 8]。
    # OLAP通常更高，75% [18, 15]。
    if workload_type == "OLAP":
        mem = int(mem_gb * 0.75)
    else:
        mem = int(mem_gb * 0.65)
    config['effective_cache_size'] = f"{mem}GB"

    # work_mem: 排序或哈希操作内存，默认4MB [1, 13, 16]。
    # OLTP谨慎增加16MB-64MB [1, 15, 3]。OLAP较高256MB-1GB+ [1, 18, 15, 3]。
    print(mem, shared_buffers, max_connections)
    base_work_mem = (mem_gb * 0.8 - shared_buffers) / max_connections
    if workload_type == "OLTP":
        config['work_mem'] = f"128MB"  # 增加到32MB，仍保持谨慎
        if not is_high_performance_system:
            config['work_mem'] = "64MB"  # 低性能更保守 [4]
    else:  # OLAP
        config['work_mem'] = f"{base_work_mem}MB"  # 增加到512MB
        if not is_high_performance_system:
            config['work_mem'] = f"{min(base_work_mem,256)}MB"

    # maintenance_work_mem: 维护操作内存，默认64MB [1, 16]。
    # 显著增加以加快VACUUM和索引创建 [1, 18, 3]。
    config[
        'maintenance_work_mem'] = f"{min(int(mem_gb * mem_multiplier_maintenance_work * 1024), 2048 if is_high_performance_system else 512)}MB"  # 高性能上限2GB，低性能上限512MB [3]

    # wal_buffers: WAL记录缓冲内存，默认-1 (约3% shared_buffers) [13, 16, 6]。
    # 高写入系统增加 [1, 2, 3, 6, 8, 7, 9, 19]。
    config['wal_buffers'] = f"{wal_buffers_mb}MB"

    # 2. WAL参数
    config['wal_level'] = "replica"  # 默认用于流复制 [3, 20, 21, 22]
    config['max_wal_size'] = f"{max_wal_size_gb}GB"  # 默认1GB [3, 9, 10]
    config['min_wal_size'] = f"{int(max_wal_size_gb * 0.25)}GB"  # 通常为max_wal_size的25% [3, 9]
    config['checkpoint_completion_target'] = "0.9"  # 默认0.9，推荐值 [1, 3, 7, 9]

    # checkpoint_timeout: 默认5分钟 [1, 9]。
    # OLTP保持适中5分钟，OLAP可增加到10-15分钟 [18, 3, 7]。
    if workload_type == "OLTP":
        config['checkpoint_timeout'] = "5min"
    else:  # OLAP
        config['checkpoint_timeout'] = "15min"

    # 微调模式下的WAL参数
    if is_vm and is_cow_filesystem:  # 虚拟机且使用COW文件系统 [2]
        config['wal_recycle'] = "off"
        config['wal_init_zero'] = "off"
    if fine_tune_mode:
        # wal_compression: CPU充足且I/O是瓶颈时考虑启用 [2, 7]
        if input("是否启用WAL压缩 (wal_compression)？(y/n): ").strip().lower() == 'y':
            config['wal_compression'] = "on"

    # 3. 连接参数
    # max_connections: 默认100 [3]。
    # 强烈建议使用连接池 (如PgBouncer) [1, 3, 23, 24]。
    # OLTP连接数可能较高，OLAP可能较低。
    config['max_connections'] = "200"  # 配合连接池，OLTP基线 [3]
    if workload_type == "OLAP":
        config['max_connections'] = "50"  # OLAP连接数通常较低 [3]

    # 微调模式下的连接和会话管理参数
    if fine_tune_mode:
        # statement_timeout: 默认0 (禁用) [3, 23, 6, 19, 25]。
        # 建议设置为合理值，防止长时间查询耗尽资源 [3, 19]。
        if log_slow_query_threshold_ms is not None and log_slow_query_threshold_ms > 0:
            config['statement_timeout'] = f"{log_slow_query_threshold_ms}ms"  # 使用慢查询阈值作为基线
        else:
            timeout_input = input("请输入语句超时时间 (statement_timeout, 例如: 15min, 0表示禁用): ").strip()
            if timeout_input:
                config['statement_timeout'] = timeout_input

        # lock_timeout: 默认0 (禁用) [3]。
        # 建议设置为合理值，避免长时间锁等待 [3, 6]。
        lock_timeout_input = input("请输入锁等待超时时间 (lock_timeout, 例如: 5s, 0表示禁用): ").strip()
        if lock_timeout_input:
            config['lock_timeout'] = lock_timeout_input

        # idle_in_transaction_session_timeout: 默认0 (禁用) [3, 23, 6, 19, 25]。
        # 建议设置为合理值，防止空闲事务持有锁 [3, 19]。
        idle_timeout_input = input(
            "请输入事务中空闲会话超时时间 (idle_in_transaction_session_timeout, 例如: 5min, 0表示禁用): ").strip()
        if idle_timeout_input:
            config['idle_in_transaction_session_timeout'] = idle_timeout_input

    # 4. 异步IO / 并行查询
    # max_worker_processes: 通常是CPU核心数的2倍 [3, 7]。
    # 备用服务器必须与主服务器相同或更高。
    config['max_worker_processes'] = str(cpu_cores * 2)
    if not is_primary_server:  # 备用服务器
        # 备用服务器的max_worker_processes应至少与主服务器相同或更高。
        # 这里假设主服务器的配置是合理的，并确保备用服务器有足够的worker。
        config['max_worker_processes'] = str(max(cpu_cores * 2, 8))  # 确保至少8个，或CPU*2

    # max_parallel_workers: 默认8 [3, 26]。
    # OLAP充分利用CPU，OLTP也可能使用并行但较少 [18, 15, 3, 7, 26]。
    if workload_type == "OLAP":
        config['max_parallel_workers'] = str(max(2, int(cpu_cores * 0.75)))  # OLAP充分利用CPU [15]
        config['max_parallel_workers_per_gather'] = str(max(2, int(cpu_cores / 2)))  # 默认2 [15, 3]
        config['max_parallel_maintenance_workers'] = str(max(2, int(cpu_cores / 4)))  # 默认2 [3]
        config['parallel_setup_cost'] = "1000.0"  # 默认值可能过低
        config['parallel_tuple_cost'] = "0.1"  # 默认值可能过高
        if fine_tune_mode and expected_concurrent_analytical_queries is not None:
            if expected_concurrent_analytical_queries > 1:
                # 如果有许多并发OLAP查询，为避免CPU争用，并行worker数量应更保守 [27]
                config['max_parallel_workers'] = str(max(2, int(cpu_cores / expected_concurrent_analytical_queries)))
                config['max_parallel_workers_per_gather'] = str(
                    max(1, int(cpu_cores / (expected_concurrent_analytical_queries * 2))))
                config['parallel_tuple_cost'] = "0.01"  # 鼓励并行计划，但不过度 [27]
            else:  # 少数并发OLAP查询，可以更激进
                config['parallel_tuple_cost'] = "0.005"  # 更低的值 [27]
                config['min_parallel_table_scan_size'] = "1MB"  # 鼓励并行扫描 [27]
                config['min_parallel_index_scan_size'] = "512kB"  # 鼓励并行扫描 [27]
    else:  # OLTP
        config['max_parallel_workers'] = str(max(2, int(cpu_cores / 4)))  # OLTP也可能使用并行，但较少
        config['max_parallel_workers_per_gather'] = "2"
        config['max_parallel_maintenance_workers'] = "2"

    # effective_io_concurrency: 默认1 [2, 22]。SSD/NVMe可设高 [1, 2, 8, 28, 22]。
    # random_page_cost: 默认4.0 [3, 4, 29, 26, 14]。SSD/NVMe可设1.1 [3, 4, 29, 28, 14]。
    if storage_type in ['SSD', 'NVMe']:
        config['effective_io_concurrency'] = "200"  # SSD/NVMe较高 [2, 8, 28, 22]
        config['random_page_cost'] = "1.1"  # SSD/NVMe较低 [3, 4, 29, 28, 14]
    else:  # HDD
        config['effective_io_concurrency'] = "2"  # HDD较低，或根据RAID条带中的独立驱动器数量 [22]
        config['random_page_cost'] = "4.0"  # HDD默认 [29]
    config['seq_page_cost'] = "1.0"  # 默认1.0 [29]

    config['cpu_tuple_cost'] = "0.01"
    config['cpu_index_tuple_cost'] = "0.005"
    config['cpu_operator_cost'] = "0.0025"

    # 5. Autovacuum参数
    config['autovacuum'] = "on"
    config['autovacuum_max_workers'] = str(autovacuum_max_workers_base)  # 默认3 [3, 11]
    config['autovacuum_naptime'] = f"{autovacuum_naptime_s}s"  # 默认60s [11, 12]
    config['autovacuum_vacuum_cost_limit'] = str(autovacuum_cost_limit)  # 默认-1 (使用vacuum_cost_limit) [3, 11]

    if autovacuum_strategy == "AGGRESSIVE":
        config['autovacuum_vacuum_scale_factor'] = "0.005"  # 更早触发 (0.5%) [3, 11]
        config['autovacuum_analyze_scale_factor'] = "0.001"  # 更早触发 (0.1%) [3, 11]
        config['autovacuum_vacuum_cost_delay'] = "0ms"  # 不延迟 [11]
    elif autovacuum_strategy == "NORMAL":
        config['autovacuum_vacuum_scale_factor'] = "0.2"  # 默认0.2 [3, 11]
        config['autovacuum_analyze_scale_factor'] = "0.1"  # 默认0.1 [3, 11]
        config['autovacuum_vacuum_cost_delay'] = "2ms"  # 默认2ms [11]
    else:  # CONSERVATIVE
        config['autovacuum_vacuum_scale_factor'] = "0.4"  # 延迟触发 [11]
        config['autovacuum_analyze_scale_factor'] = "0.2"  # 延迟触发 [11]
        config['autovacuum_vacuum_cost_delay'] = "20ms"  # 延迟更长 [11]

    # 6. 日志 (推荐设置)
    config['log_destination'] = "'stderr'"  # 默认stderr [30]
    if fine_tune_mode and log_destination_type:
        if log_destination_type == "csvlog":
            config['log_destination'] = "'csvlog'"  # [31, 30]
        elif log_destination_type == "jsonlog":
            config['log_destination'] = "'jsonlog'"  # [30]
        elif log_destination_type == "syslog":
            config['log_destination'] = "'syslog'"  # [31, 30]
            # Syslog通常会提供自己的时间戳和PID，因此前缀中可以省略 [30]
            config['log_line_prefix'] = "'%q%u@%d/%a '"
        else:  # stderr
            config['log_destination'] = "'stderr'"

    config['logging_collector'] = "on"  # 默认off [2, 30]
    config['log_directory'] = "'log'"  # 默认log (数据目录内) [2, 30]
    config['log_filename'] = "'postgresql-%Y-%m-%d_%H%M%S.log'"  # 默认值 [30]
    config['log_min_duration_statement'] = "500ms"  # 默认-1 (禁用) [1, 5, 2, 3, 23, 6, 31, 30]
    if fine_tune_mode and log_slow_query_threshold_ms is not None:
        config['log_min_duration_statement'] = f"{log_slow_query_threshold_ms}ms"

    config['log_line_prefix'] = "'%m [%p] %q%u@%d '"  # 常用日志前缀 [2, 31, 30]
    config['log_connections'] = "on"  # 默认off [3, 30]
    config['log_disconnections'] = "on"  # 默认off [3, 30]
    config['log_lock_waits'] = "on"  # 默认off [2, 3, 6, 30]
    config['log_autovacuum_min_duration'] = "0"  # 记录所有autovacuum活动 [2, 30]

    if fine_tune_mode:
        if log_rotation_age_hours is not None and log_rotation_age_hours > 0:
            config['log_rotation_age'] = f"{log_rotation_age_hours}h"  # 默认24小时 [31, 30]
        if log_rotation_size_mb is not None and log_rotation_size_mb > 0:
            config['log_rotation_size'] = f"{log_rotation_size_mb}MB"  # 默认10MB [31, 30]
        config['log_truncate_on_rotation'] = "on"  # 默认off [30]

    # 7. 其他常用设置
    config['listen_addresses'] = "'*'"  # 生产环境允许所有IP连接，但需防火墙控制 [3, 6]
    config['port'] = "5432"  # 默认5432 [3, 6]
    config['max_locks_per_transaction'] = "64"
    config['max_prepared_transactions'] = "0"  # 如果不使用两阶段提交，设为0
    config['hot_standby'] = "on"  # 开启只读查询 [21, 22]

    # 8. 复制特定参数 (主服务器)
    if is_primary_server:
        config[
            'wal_level'] = f"'{replication_type.lower()}'"  # physical streaming -> replica, logical -> logical [3, 20, 21, 22]
        if replica_count is not None:
            config['max_wal_senders'] = str(max(5, replica_count + 2))  # 至少5个，或副本数+缓冲 [3, 20]
        else:
            config['max_wal_senders'] = "10"  # 默认值 [3]
        config['archive_mode'] = "on"  # 启用WAL归档 [2, 3, 20, 32]
        # archive_command 需要用户输入，在main函数中处理

        # synchronous_commit: 默认on [1, 18]。
        # 权衡数据一致性与写入性能 [1, 18, 3, 20]。
        if replication_type == "Physical Streaming":
            if rpo_tolerance == "Low":  # 强一致性，无数据丢失 [20, 33]
                config['synchronous_commit'] = "on"
            elif rpo_tolerance == "Medium":  # 可接受少量数据丢失以换取性能
                config['synchronous_commit'] = "local"
            else:  # 高容忍度，最大性能
                config['synchronous_commit'] = "off"

            # wal_keep_size (微调)
            if fine_tune_mode:
                wal_keep_size_input = input("请输入WAL保留大小 (wal_keep_size, 例如: 1GB, 0表示禁用): ").strip()
                if wal_keep_size_input:
                    config['wal_keep_size'] = wal_keep_size_input  # [3, 6, 9, 20]

    # 9. 复制特定参数 (备用服务器)
    else:  # 如果不是主服务器，则假定是备用服务器
        # hot_standby_feedback: 默认off [33, 21, 34, 35, 22]。
        # 避免备用服务器查询取消，但可能导致主服务器膨胀 [33, 34, 35]。
        if fine_tune_mode:
            if standby_usage_type == "OLAP_Long_Running":
                config['hot_standby_feedback'] = "on"
            else:  # OLTP_Read_Replica 或 General
                config['hot_standby_feedback'] = "off"

    # default_statistics_target: 默认100 [3]。
    # OLAP需要更高值500+ [18, 3]。
    if workload_type == "OLAP":
        config['default_statistics_target'] = "500"
    else:  # OLTP
        config['default_statistics_target'] = "100"

    return config


def parse_current_config(config_path):
    """解析当前 postgresql.conf 文件，返回参数字典。"""
    current_config = {}
    if not os.path.exists(config_path):
        return current_config

    with open(config_path, 'r') as f:
        for line in f:
            line = line.strip()
            # 忽略注释和空行
            if not line or line.startswith('#'):
                continue
            # 匹配参数行，例如：key = value # comment
            match = re.match(r'^\s*([a-zA-Z0-9_]+)\s*=\s*(.*?)\s*(?:#.*)?$', line)
            if match:
                key = match.group(1).strip()
                value = match.group(2).strip().strip("'")  # 移除可能的单引号
                current_config[key] = value
    return current_config


def write_new_config(config_path, new_config_params):
    """将新配置写入文件，保留原有文件的注释和未更改的参数。"""
    temp_config_path = config_path + ".new"
    old_lines = config_path + '.conf'
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            old_lines = f.readlines()

    # 用于追踪哪些参数已经被新配置覆盖
    updated_keys = set()

    with open(temp_config_path, 'w') as f_out:
        for line in old_lines:
            line_stripped = line.strip()
            # 忽略data_directory行，因为它通常由PGDATA环境变量或initdb设置
            if line_stripped.startswith("data_directory"):
                continue

            if not line_stripped or line_stripped.startswith('#'):
                f_out.write(line)  # 保留注释和空行
                continue

            match = re.match(r'^\s*([a-zA-Z0-9_]+)\s*=\s*(.*?)\s*(?:#.*)?$', line_stripped)
            if match:
                key = match.group(1).strip()
                if key in new_config_params:
                    # 使用新值替换原有参数行
                    value = new_config_params[key]
                    # 对于字符串类型，根据需要添加引号 [18]
                    if isinstance(value, str) and not (value.startswith("'") and value.endswith("'")):
                        f_out.write(f"{key} = '{value}'\n")
                    else:
                        f_out.write(f"{key} = {value}\n")
                    updated_keys.add(key)
                else:
                    # 保留未被新配置覆盖的现有参数行
                    f_out.write(line)
            else:
                # 保留不符合参数格式的行
                f_out.write(line)

        # 添加新配置中未在旧文件中出现的参数
        f_out.write("\n# --- New parameters added by script ---\n")
        for key, value in new_config_params.items():
            if key not in updated_keys:
                if isinstance(value, str) and not (value.startswith("'") and value.endswith("'")):
                    f_out.write(f"{key} = '{value}'\n")
                else:
                    f_out.write(f"{key} = {value}\n")
    return temp_config_path


def diff_configs(old_config, new_config):
    """比较新旧配置并输出差异。"""
    print("\n--- 配置参数变化 ---")
    modified_params = {}
    added_params = {}

    # 检查修改和新增
    for key, new_val in new_config.items():
        if key in old_config:
            if old_config[key] != new_val:
                modified_params[key] = (old_config[key], new_val)
        else:
            added_params[key] = new_val

    if modified_params:
        print("\n--- 修改的参数 ---")
        for key, (old_val, new_val) in modified_params.items():
            print(f"参数: {key}\n  旧值: {old_val}\n  新值: {new_val}\n")
    else:
        print("\n--- 没有修改的参数 ---")

    if added_params:
        print("\n--- 新增的参数 ---")
        for key, value in added_params.items():
            print(f"参数: {key}\n  新值: {value}\n")
    else:
        print("\n--- 没有新增的参数 ---")

    # 注意: 此脚本不会从配置文件中主动删除参数，
    # 所以通常不会有“移除的参数”这一类。


def main():
    print("--- PostgreSQL 配置文件生成器 ---")

    # 1. 获取系统信息
    auto_detect = input("是否自动检测服务器性能 (仅限 Linux/Unix, y/n)? ").strip().lower()
    cpu_cores, mem_gb = None, None

    if auto_detect == 'y':
        cpu_cores, mem_gb = get_system_info_with_commands()
        if cpu_cores is not None and mem_gb is not None:
            print(f"自动检测到 CPU 核心数: {cpu_cores}, 总内存: {mem_gb}GB")
        else:
            print("自动检测失败或获取到无效信息，请手动输入。")
            cpu_cores, mem_gb = get_user_input_system_info()
    else:
        cpu_cores, mem_gb = get_user_input_system_info()

    # 2. 获取工作负载类型
    workload_type = get_workload_type()

    # 3. 获取Autovacuum策略
    autovacuum_strategy = get_autovacuum_strategy()

    # 新增输入：服务器环境和性能
    is_vm = input("服务器是虚拟机吗 (y/n)? ").strip().lower() == 'y'
    _max_connections = input("最大连接数是多少？留空默认100.").strip().lower()
    max_connections = int(_max_connections) if _max_connections else 100
    storage_map = {
        "1": 'SSD', "2": 'NVMe', "3": 'HDD'
    }
    storage_type = ""
    while storage_type not in ['SSD', 'NVMe', 'HDD']:
        _storage_type = input("请输入存储类型对应的数字 (1.SSD/2.NVMe/3.HDD): ").strip()
        storage_type = storage_map[_storage_type]
        if storage_type not in ['SSD', 'NVMe', 'HDD']:
            print("无效的存储类型，请选择 'SSD', 'NVMe' 或 'HDD'。")

    is_high_performance_system = input("这是高性能服务器吗 (y/n)? ").strip().lower() == 'y'

    # 新增输入：双机主备架构
    is_primary_server = input("这是双机主备架构中的主服务器吗 (y/n)? ").strip().lower() == 'y'
    replication_type = None
    rpo_tolerance = None
    replica_count = None
    standby_usage_type = None

    if is_primary_server:
        replication_type = ""
        while replication_type not in ['Physical Streaming', 'Logical']:
            replication_type = input("请选择复制类型 (Physical Streaming / Logical): ").strip()
            if replication_type not in ['Physical Streaming', 'Logical']:
                print("无效的复制类型，请选择 'Physical Streaming' 或 'Logical'。")

        if replication_type == "Physical Streaming":
            rpo_tolerance = ""
            while rpo_tolerance not in ["Low", "Medium", "High"]:
                rpo_tolerance = input("您对数据丢失的容忍度如何 (Low / Medium / High)? ").strip()
                if rpo_tolerance not in ["Low", "Medium", "High"]:
                    print("无效的容忍度，请选择 'Low', 'Medium' 或 'High'。")

        while True:
            try:
                replica_count_str = input("请输入计划连接的副本数量 (例如: 1): ").strip()
                replica_count = int(replica_count_str)
                if replica_count < 0:
                    raise ValueError
                break
            except ValueError:
                print("无效的副本数量，请输入非负整数。")
    else:  # 备用服务器
        standby_usage_type = ""
        while standby_usage_type not in ['OLAP_Long_Running', 'OLTP_Read_Replica', 'General']:
            standby_usage_type = input(
                "备用服务器主要用于什么目的 (OLAP_Long_Running / OLTP_Read_Replica / General)? ").strip()
            if standby_usage_type not in ['OLAP_Long_Running', 'OLTP_Read_Replica', 'General']:
                print("无效的备用服务器用途，请选择 'OLAP_Long_Running', 'OLTP_Read_Replica' 或 'General'。")

    is_cow_filesystem = None
    if is_vm:
        is_cow_filesystem = input("您的数据/WAL卷是否使用写时复制文件系统 (如ZFS或Btrfs, y/n)? ").strip().lower() == 'y'

    # 微调模式
    fine_tune_mode = input("是否进入微调模式 (y/n)? ").strip().lower() == 'y'

    expected_concurrent_analytical_queries = None
    log_slow_query_threshold_ms = None
    log_destination_type = None
    log_rotation_age_hours = None
    log_rotation_size_mb = None
    archive_command_input = None

    if fine_tune_mode:
        if workload_type == "OLAP":
            while True:
                try:
                    concurrent_queries_str = input("请输入预期的并发分析查询数量 (例如: 2): ").strip()
                    expected_concurrent_analytical_queries = int(concurrent_queries_str)
                    if expected_concurrent_analytical_queries <= 0:
                        raise ValueError
                    break
                except ValueError:
                    print("无效的并发查询数量，请输入正整数。")

        while True:
            try:
                slow_query_threshold_str = input(
                    "请输入慢查询日志的最小持续时间 (毫秒, 例如: 1000, 0表示记录所有): ").strip()
                log_slow_query_threshold_ms = int(slow_query_threshold_str)
                if log_slow_query_threshold_ms < 0:
                    raise ValueError
                break
            except ValueError:
                print("无效的慢查询阈值，请输入非负整数。")

        log_destination_type = ""
        while log_destination_type not in ["stderr", "csvlog", "jsonlog", "syslog"]:
            log_destination_type = input("请选择日志目标类型 (stderr / csvlog / jsonlog / syslog): ").strip().lower()
            if log_destination_type not in ["stderr", "csvlog", "jsonlog", "syslog"]:
                print("无效的日志目标类型，请选择 'stderr', 'csvlog', 'jsonlog' 或 'syslog'。")

        while True:
            try:
                log_rotation_age_str = input(
                    "请输入日志文件最大使用时间{log_rotation_age}，如留空为24小时 (小时, 例如: 6, 0表示禁用): ").strip()
                if log_rotation_age_str == '':
                    return 24
                log_rotation_age_hours = int(log_rotation_age_str)
                if log_rotation_age_hours < 0:
                    raise ValueError
                break
            except ValueError:
                print("无效的日志轮换时间，请输入非负整数。")

        while True:
            try:
                log_rotation_size_str = input(
                    "请输入日志文件最大大小{log_rotation_size}，如留空为10MB (MB, 例如: 1024, 0表示禁用): ").strip()
                if not log_rotation_age_str:
                    return 10
                log_rotation_size_mb = int(log_rotation_size_str)
                if log_rotation_size_mb < 0:
                    raise ValueError
                break
            except ValueError:
                print("无效的日志轮换大小，请输入非负整数。")

        if is_primary_server:
            archive_command_input = input(
                "请输入WAL归档命令 (archive_command, 例如: 'cp %p /path/to/archive/%f', 留空表示不设置): ").strip()

    # 4. 生成配置
    generated_config = generate_config(
        cpu_cores, mem_gb, workload_type, autovacuum_strategy,
        is_vm, storage_type, is_high_performance_system,
        is_primary_server, max_connections, replication_type, rpo_tolerance,
        is_cow_filesystem, expected_concurrent_analytical_queries,
        log_slow_query_threshold_ms, log_destination_type,
        log_rotation_age_hours, log_rotation_size_mb,
        standby_usage_type, replica_count, fine_tune_mode
    )

    # 如果用户在微调模式下提供了 archive_command，则添加到配置中
    if fine_tune_mode and is_primary_server and archive_command_input:
        generated_config['archive_command'] = f"'{archive_command_input}'"

    # 5. 输出或修改文件
    output_only = input("只输出配置参数而不修改文件 (y/n)? ").strip().lower()

    if output_only == 'y':
        print("\n--- 生成的 PostgreSQL 配置参数 ---")
        for key, value in generated_config.items():
            print(f"{key} = {value}")

        print("\n--- 操作系统级别调优建议 ---")
        print("为了进一步优化PostgreSQL性能，建议考虑以下操作系统级别调优：")
        print("1. 禁用透明大页 (Transparent Huge Pages, THP)：THP可能导致PostgreSQL性能下降。")
        print("   - 对于RHEL/CentOS系统，可以使用 `tuned-adm profile edbpostgres` 或手动禁用。")
        print("2. 禁用TCP时间戳：有助于减少时间戳生成引起的性能峰值。")
        print("3. 禁用atime：PostgreSQL不依赖数据文件的atime，禁用可节省CPU周期。")
        print("   - 在 `/etc/fstab` 中为PostgreSQL数据和WAL驱动器添加 `noatime,nodiratime` 选项。")
        print("4. 启用大页 (Huge Pages)：如果操作系统支持，可以提升PostgreSQL性能。")
        print("5. 磁盘布局：将WAL磁盘与数据磁盘分开，并使用RAID 1或RAID 10以提高冗余和性能。")
        print("6. 连接池：强烈建议在应用程序和数据库之间使用连接池（如PgBouncer），以高效管理连接并减少数据库服务器的开销。")
        print("\n请注意：这些是操作系统级别的建议，需要谨慎操作并根据您的具体环境进行调整。")

    else:
        postgres_conf_path = input(
            "请输入 postgresql.conf 的完整路径 (例如: /etc/postgresql/16/main/postgresql.conf): ").strip()
        if not os.path.exists(postgres_conf_path):
            print(f"警告: {postgres_conf_path} 不存在。将创建新文件。")

        # 备份旧文件
        backup_path = f"{postgres_conf_path}.bak.{os.times().elapsed}"
        if os.path.exists(postgres_conf_path):
            print(f"备份原有配置文件到: {backup_path}")
            shutil.copy2(postgres_conf_path, backup_path)

        # 解析旧配置
        old_config_params = parse_current_config(postgres_conf_path)

        # 写入新配置到临时文件
        temp_new_config_path = write_new_config(postgres_conf_path, generated_config)

        # 替换旧文件
        try:
            shutil.move(temp_new_config_path, postgres_conf_path)
            print(f"已成功生成新的配置文件: {postgres_conf_path}")

            # 比较并输出差异
            new_config_params_after_write = parse_current_config(postgres_conf_path)  # 重新解析新写入的文件
            diff_configs(old_config_params, new_config_params_after_write)

            print("\n请注意: 修改配置文件后，您可能需要重启 PostgreSQL 服务才能使更改生效。")
            print("\n--- 操作系统级别调优建议 ---")
            print("为了进一步优化PostgreSQL性能，建议考虑以下操作系统级别调优：")
            print("1. 禁用透明大页 (Transparent Huge Pages, THP)：THP可能导致PostgreSQL性能下降。")
            print("   - 对于RHEL/CentOS系统，可以使用 `tuned-adm profile edbpostgres` 或手动禁用。")
            print("2. 禁用TCP时间戳：有助于减少时间戳生成引起的性能峰值。")
            print("3. 禁用atime：PostgreSQL不依赖数据文件的atime，禁用可节省CPU周期。")
            print("   - 在 `/etc/fstab` 中为PostgreSQL数据和WAL驱动器添加 `noatime,nodiratime` 选项。")
            print("4. 启用大页 (Huge Pages)：如果操作系统支持，可以提升PostgreSQL性能。")
            print("5. 磁盘布局：将WAL磁盘与数据磁盘分开，并使用RAID 1或RAID 10以提高冗余和性能。")
            print(
                "6. 连接池：强烈建议在应用程序和数据库之间使用连接池（如PgBouncer），以高效管理连接并减少数据库服务器的开销。")
            print("\n请注意：这些是操作系统级别的建议，需要谨慎操作并根据您的具体环境进行调整。")

        except Exception as e:
            print(f"写入文件失败: {e}")
            if os.path.exists(temp_new_config_path):
                os.remove(temp_new_config_path)  # 清理临时文件


if __name__ == "__main__":
    main()
